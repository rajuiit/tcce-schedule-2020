
<!DOCTYPE html>
<html lang="en">
<head>
    <title>Keynote Speakers</title>
    <?php include 'include.php'; ?>
    <link href="css/speaker.css" rel="stylesheet"/>
</head>
<body>
<?php include 'navbar_non_static.php';?>
<div class="container">

    <div class="row presentation presentation-video">
          <div class="col-md-12">
              <div class="card">
                <video id="myVideo" controls="controls" height="auto" width="740">
                  <source id="video_player" src="#" type="video/mp4"></source>
                </video>
                <div class="session-information">
                    <h3 id="sessin_name">Key Note 8</h3>
                    <h5 class="card-title">Ryad Benosman, 
Professor with University of Pittsburgh Medical Center,
Adjunct professor at CMU Robotics Institute and Professor with Sorbonne University,
leading the Neuromorphic Vision and Natural Computation Laboratory, at the Eye and Ear Institute in Pittsburgh



</h5>
                </div>
                <div class="clearfix">

                </div>
              </div>
          </div>
    </div>
    <div class="row">
      <div class="col-md-12 pre-head pre-head-video">
         <div class="text-container">
           <h3><i class="fa fa-television" aria-hidden="true"></i> KEY NOTE 8 PRESENTATION</h3>

<hr>
 </div>
 <h4>
</h4>
 <hr>
<h3>Abstract:</h3>
<p align="justify">

There has been significant research over the past two decades in developing new systems for spiking neural computation. The impact of neuromorphic concepts on recent developments in optical sensing, display and artificial vision is presented. State-of-the-art image sensors suffer from severe limitations imposed by their very principle of operation. These sensors acquire the visual information as a series of ’snapshots’ recorded at discrete point in time, hence time-quantized at a predetermined frame rate, resulting in limited temporal resolution, low dynamic range and a high degree of redundancy in the acquired data. Nature suggests a different approach: Biological vision systems are driven and controlled by events happening within the scene in view, and not — like image sensors — by artificially created timing and control signals that have no relation whatsoever to the source of the visual information. Translating the frameless paradigm of biological vision to artificial imaging systems implies that control over the acquisition of visual information is no longer being imposed externally to an array of pixels but the decision making is transferred to the single pixel that handles its own information individually. It is demonstrated that bio-inspired vision systems have the potential to outperform conventional, frame-based vision acquisition and processing systems in many application fields and to establish new benchmarks in terms of redundancy suppression/data compression, dynamic range, temporal resolution and power efficiency to realize advanced functionality like 3D vision, object tracking, motor control, visual feedback loops and even allow us to rethink our current paradigm of computation. The ultimate goal is to develop brain-inspired general purpose computation architectures that can breach the current bottleneck introduced by the von Neumann architecture.
Ryad Benosman is Professor with University of Pittsburgh Medical Center, adjunct professor at CMU Robotics Institute and Professor with Sorbonne University, leading the Neuromorphic Vision and Natural Computation Laboratory, at the Eye and Ear Institute in Pittsburgh. He received the M.Sc. and Ph.D. degrees in applied mathematics and robotics from University Pierre and Marie Curie in 1994 and 1999, respectively. His work covers neuromorphic visual computation and sensing and event-based computation. He is currently involved in the French retina prosthetics project and in the development of retina implants and cofounder of Pixium Vision a French prosthetics company. He also actively works on retina stimulation using optogenetics with Gensight Biologics. He is also a cofounder of Chronocam a company developing Event based cameras and event driven computation systems. He is an expert in complex perception systems, which embraces the conception, design, and use of different vision sensors covering omnidirectional 360 degree wide field of view cameras, variant scale sensors, and non-central sensors. He is among the pioneers of the domain of omni-directional vision and unusual cameras and still active in this domain. He has been involved in several national and European robotics projects, mainly in the design of artificial visual loops and sensors. His current research interests include the understanding of the computation operated along the visual systems areas and establishing a link between computational and biological vision. Ryad Benosman has authored more than 100 scientific publications and holds several patents in the area of vision, robotics, event-based sensing and prosthetics.



 


</p>

        
      </div>
    </div>
    




    </div>
</div>
<?php include 'footer.php';?>
</body>


</html>